{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks for H.P Lovecraft text generation\n",
    "\n",
    "\"The color out of space\" is one of my favorite tales from Lovecraft, i will use it(as well as others as the call of cthulhu) to create a recurrent neural network in tensorflow that learns his style and generates new text in his style\n",
    "\n",
    "This network is based off of Andrej Karpathy's [post on RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and [implementation in Torch](https://github.com/karpathy/char-rnn) and an example from \"Deep Learning Nanodegree\" on udacity. Also, some information [here at r2rt](http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html) and from [Sherjil Ozair](https://github.com/sherjilozair/char-rnn-tensorflow) on GitHub. \n",
    "\n",
    "## General architecture using \"Long short term memory\" units in the recurrent layers\n",
    "\n",
    "<img src=\"assets/charseq.jpeg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime ,localtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only the  first time nltk is used to download language\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define conf variables and hyper parameteters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode = \"characters\" #characters or words\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 128       # Sequences per batch\n",
    "num_steps = 75         # Number of sequence steps per batch\n",
    "lstm_size = 768         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "learning_rate = 0.0005    # Learning rate\n",
    "keep_prob = 1       # Dropout keep probability\n",
    "\n",
    "resume_from_checkpoint = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base text\n",
    "Once trained ,the network can take base text and a sequence size and generate new text using base text as first characters in the sequence. For every element in base text wi will create a list that will store generated text as training goes, to be able to compare results between steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_try = [\"In the first place\",\"the night before\",\"horror\",\"creature\",\"night\",\"dream\",\"thing\",\"That night\",\"mountain\",\"Ammi\",\"Cthulhu\",\"raven\",\"bird\",\"nevermore\",\"dead\",\"The bird\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that separates text into tokens(for whitespace characters, only new line is implemented, missing tabs and others="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " ',',\n",
       " ' ',\n",
       " 'm',\n",
       " 'y',\n",
       " ' ',\n",
       " 'n',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'L',\n",
       " 'u',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'L',\n",
       " 'e',\n",
       " 'a',\n",
       " 'l',\n",
       " '!',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'F',\n",
       " 'r',\n",
       " 'o',\n",
       " 'm',\n",
       " ' ',\n",
       " 'G',\n",
       " 'u',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 'm',\n",
       " 'a',\n",
       " 'l',\n",
       " 'a']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_by_words(text):\n",
    "    text = text.replace(\"\\n\",\" new_line_token \")\n",
    "    tokens = []\n",
    "    splitted =[[word_tokenize(w),' ']for w in text.split()]\n",
    "    splitted = list(itertools.chain(*list(itertools.chain(*splitted))))\n",
    "    \n",
    "    token_list = []\n",
    "    i = 0\n",
    "    while i < len(splitted):\n",
    "        if splitted[i] == \"new_line_token\":\n",
    "            if   token_list[-1]==\" \":\n",
    "                token_list[-1] = splitted[i]\n",
    "            else:\n",
    "                token_list.append(splitted[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            token_list.append(splitted[i])\n",
    "        i+=1\n",
    "    \n",
    "    return token_list\n",
    "\n",
    "def tokenize_by_characters(text):\n",
    "    return list(text)\n",
    "\n",
    "def tokenize_text(text,mode=\"characters\"):\n",
    "    if mode == \"characters\":\n",
    "        return tokenize_by_characters(text)\n",
    "    elif mode == \"words\":\n",
    "        return tokenize_by_words(text)\n",
    "    \n",
    "tokenize_text(\"Hello, my name is Luis Leal!\\n\\nFrom Guatemala\",mode)\n",
    "#tokenize_text(\"Hello, my name is Luis Leal!\\n\\nFrom Guatemala\",\"words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll load the text file and convert it into integers for our network to use. Here I'm creating a couple dictionaries to convert the characters to and from integers. Encoding the characters as integers makes it easier to use as input in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'r') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set(tokenize_text(text,mode))\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a little portion of text for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_text = tokenize_text(text,mode)\n",
    "encoded_dataset = np.array([vocab_to_int[c] for c in tokenized_text if c in vocab_to_int], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_size = batch_size * num_steps #create a single baty\n",
    "validation_start_index = len(encoded_dataset) - validation_size\n",
    "\n",
    "encoded = encoded_dataset[:validation_start_index]\n",
    "encoded_val = encoded_dataset[validation_start_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r genera of creatures are germinated) -- the spontaneous germination, I say, of five vast hordes of \n"
     ]
    }
   ],
   "source": [
    "def encoded_to_text(encoded):\n",
    "    return \"\".join([int_to_vocab[number] for number in encoded])\n",
    "\n",
    "print(encoded_to_text(encoded_val[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_text =encoded_to_text(encoded_val)\n",
    "text = encoded_to_text(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the first 100 characters of train and validation, make sure everything is peachy.  line of a book ever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE COLOUR OUT OF SPACE\\n\\nWest of Arkham the hills rise wild, and there are valleys with deep woods t'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r genera of creatures are germinated) -- the spontaneous germination, I say, of five vast hordes of '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the characters encoded as integersin both train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 52,  89,  70,  96,  72,  27,  58,  27,  97,  51,  96,  27,  97,\n",
       "        52,  96,  27,  60,  96,  53,  39,  57,  72,  70,  11,  11,  24,\n",
       "        61,  79,  84,  96,  56,   6,  96,  57,  48,  47,   8,  19,  73,\n",
       "        96,  84,   8,  61,  96,   8,  99,  95,  95,  79,  96,  48,  99,\n",
       "        79,  61,  96,   5,  99,  95, 100,  30,  96,  19,  34, 100,  96,\n",
       "        84,   8,  61,  48,  61,  96,  19,  48,  61,  96,  66,  19,  95,\n",
       "        95,  61,  42,  79,  96,   5,  99,  84,   8,  96, 100,  61,  61,\n",
       "        77,  96,   5,  56,  56, 100,  79,  96,  84], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 48,  96,  20,  61,  34,  61,  48,  19,  96,  56,   6,  96,  82,\n",
       "        48,  61,  19,  84,  33,  48,  61,  79,  96,  19,  48,  61,  96,\n",
       "        20,  61,  48,  73,  99,  34,  19,  84,  61, 100,  38,  96,  15,\n",
       "        15,  96,  84,   8,  61,  96,  79,  77,  56,  34,  84,  19,  34,\n",
       "        61,  56,  33,  79,  96,  20,  61,  48,  73,  99,  34,  19,  84,\n",
       "        99,  56,  34,  30,  96,  31,  96,  79,  19,  42,  30,  96,  56,\n",
       "         6,  96,   6,  99,  66,  61,  96,  66,  19,  79,  84,  96,   8,\n",
       "        56,  48, 100,  61,  79,  96,  56,   6,  96], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_val[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the network is working with individual english tokens, it's similar to a classification problem in which we are trying to predict the next character from the previous text.  Here's how many 'classes' our network has to pick from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making training mini-batches\n",
    "\n",
    "Here is where we'll make our mini-batches for training. Remember that we want our batches to be multiple sequences of some desired number of sequence steps. Considering a simple example, our batches would look like this:\n",
    "\n",
    "<img src=\"assets/sequence_batching@1x.png\" width=500px>\n",
    "\n",
    "\n",
    "<br>\n",
    "We have our text encoded as integers as one long array in `encoded`. Let's create a function that will give us an iterator for our batches. I like using [generator functions](https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/) to do this. Then we can pass `encoded` into this function and get our batch generator.\n",
    "\n",
    "The first thing we need to do is discard some of the text so we only have completely full batches. Each batch contains $N \\times M$ characters, where $N$ is the batch size (the number of sequences) and $M$ is the number of steps. Then, to get the number of batches we can make from some array `arr`, you divide the length of `arr` by the batch size. Once you know the number of batches and the batch size, you can get the total number of characters to keep.\n",
    "\n",
    "After that, we need to split `arr` into $N$ sequences. You can do this using `arr.reshape(size)` where `size` is a tuple containing the dimensions sizes of the reshaped array. We know we want $N$ sequences (`n_seqs` below), let's make that the size of the first dimension. For the second dimension, you can use `-1` as a placeholder in the size, it'll fill up the array with the appropriate data for you. After this, you should have an array that is $N \\times (M * K)$ where $K$ is the number of batches.\n",
    "\n",
    "Now that we have this array, we can iterate through it to get our batches. The idea is each batch is a $N \\times M$ window on the array. For each subsequent batch, the window moves over by `n_steps`. We also want to create both the input and target arrays. Remember that the targets are the inputs shifted over one character. You'll usually see the first input character used as the last target character, so something like this:\n",
    "```python\n",
    "y[:, :-1], y[:, -1] = x[:, 1:], x[:, 0]\n",
    "```\n",
    "where `x` is the input batch and `y` is the target batch.\n",
    "\n",
    "The way I like to do this window is use `range` to take steps of size `n_steps` from $0$ to `arr.shape[1]`, the total number of steps in each sequence. That way, the integers you get from `range` always point to the start of a batch, and each window is `n_steps` wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       n_seqs x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       n_seqs: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    # Get the batch size and number of batches we can make\n",
    "    batch_size = n_seqs * n_steps \n",
    "    n_batches =  len(arr)//batch_size\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr =  arr[:n_batches*batch_size]\n",
    "    \n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs,-1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:,n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros(x.shape)\n",
    "        y[:,:-1],y[:,-1] = x[:,1:] ,x[:,0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll make my data sets and we can check out what's going on here. Here I'm going to use a batch size of 10 and 50 sequence steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[ 52  89  70  96  72  27  58  27  97  51]\n",
      " [ 96  79  61  84  96  19  77  77  61  19]\n",
      " [ 96  82  19  66  61  48  34  56  33  79]\n",
      " [ 61 100  96  95  56  56  77   8  56  95]\n",
      " [ 84  95  42  96  84  56  96  19  95  95]\n",
      " [ 61  19  48  95  42  96  82  19  95  73]\n",
      " [ 61  79  96   5  61  48  61  96  19  20]\n",
      " [ 34  96  19 100  66  19  34  82  61  30]\n",
      " [ 19  82  61 100  96 100  56   5  34  96]\n",
      " [ 84  19  99  34  40  79  96  64  19  79]]\n",
      "\n",
      "y\n",
      " [[  89.   70.   96.   72.   27.   58.   27.   97.   51.   96.]\n",
      " [  79.   61.   84.   96.   19.   77.   77.   61.   19.   95.]\n",
      " [  82.   19.   66.   61.   48.   34.   56.   33.   79.   96.]\n",
      " [ 100.   96.   95.   56.   56.   77.    8.   56.   95.   61.]\n",
      " [  95.   42.   96.   84.   56.   96.   19.   95.   95.   56.]\n",
      " [  19.   48.   95.   42.   96.   82.   19.   95.   73.   30.]\n",
      " [  79.   96.    5.   61.   48.   61.   96.   19.   20.   19.]\n",
      " [  96.   19.  100.   66.   19.   34.   82.   61.   30.   96.]\n",
      " [  82.   61.  100.   96.  100.   56.    5.   34.   96.   77.]\n",
      " [  19.   99.   34.   40.   79.   96.   64.   19.   79.   61.]]\n"
     ]
    }
   ],
   "source": [
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Below is where you'll build the network. We'll break it up into parts so it's easier to reason about each bit. Then we can connect them up into the whole network.\n",
    "\n",
    "<img src=\"assets/charRNN.png\" width=500px>\n",
    "\n",
    "\n",
    "### Inputs\n",
    "\n",
    "First off we'll create our input placeholders. As usual we need placeholders for the training data and the targets. We'll also create a placeholder for dropout layers called `keep_prob`. This will be a scalar, that is a 0-D tensor. To make a scalar, you create a placeholder without giving it a size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32,[batch_size,num_steps],name=\"inputs\")\n",
    "    targets = tf.placeholder(tf.int32,[batch_size,num_steps],name=\"targets\")\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Cell\n",
    "\n",
    "Here we will create the LSTM cell we'll use in the hidden layer. We'll use this cell as a building block for the RNN. So we aren't actually defining the RNN here, just the type of cell we'll use in the hidden layer.\n",
    "\n",
    "We first create a basic LSTM cell with\n",
    "\n",
    "```python\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "```\n",
    "\n",
    "where `num_units` is the number of units in the hidden layers in the cell. Then we can add dropout by wrapping it with \n",
    "\n",
    "```python\n",
    "tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "```\n",
    "You pass in a cell and it will automatically add dropout to the inputs or outputs. Finally, we can stack up the LSTM cells into layers with [`tf.contrib.rnn.MultiRNNCell`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/rnn/MultiRNNCell). With this, you pass in a list of cells and it will send the output of one cell into the next cell. For example,\n",
    "\n",
    "```python\n",
    "tf.contrib.rnn.MultiRNNCell([cell]*num_layers)\n",
    "```\n",
    "\n",
    "This might look a little weird if you know Python well because this will create a list of the same `cell` object. However, TensorFlow will create different weight matrices for all `cell` objects. Even though this is actually multiple LSTM cells stacked on each other, you can treat the multiple layers as one cell.\n",
    "\n",
    "We also need to create an initial cell state of all zeros. This can be done like so\n",
    "\n",
    "```python\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size\n",
    "\n",
    "    '''\n",
    "    ### Build the LSTM Cell\n",
    "    # Use a basic LSTM cell\n",
    "    # Add dropout to the cell outputs\n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper( tf.contrib.rnn.BasicLSTMCell(lstm_size),output_keep_prob = keep_prob) for _ in range(num_layers)])\n",
    "    initial_state = cell.zero_state(batch_size,tf.float32)\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Output\n",
    "\n",
    "Here we'll create the output layer. We need to connect the output of the RNN cells to a full connected layer with a softmax output. The softmax output gives us a probability distribution we can use to predict the next character, so we want this layer to have size $C$, the number of classes/characters we have in our text.\n",
    "\n",
    "If our input has batch size $N$, number of steps $M$, and the hidden layer has $L$ hidden units, then the output is a 3D tensor with size $N \\times M \\times L$. The output of each LSTM cell has size $L$, we have $M$ of them, one for each sequence step, and we have $N$ sequences. So the total size is $N \\times M \\times L$. \n",
    "\n",
    "We are using the same fully connected layer, the same weights, for each of the outputs. Then, to make things easier, we should reshape the outputs into a 2D tensor with shape $(M * N) \\times L$. That is, one row for each sequence and step, where the values of each row are the output from the LSTM cells. We get the LSTM output as a list, `lstm_output`. First we need to concatenate this whole list into one array with [`tf.concat`](https://www.tensorflow.org/api_docs/python/tf/concat). Then, reshape it (with `tf.reshape`) to size $(M * N) \\times L$.\n",
    "\n",
    "One we have the outputs reshaped, we can do the matrix multiplication with the weights. We need to wrap the weight and bias variables in a variable scope with `tf.variable_scope(scope_name)` because there are weights being created in the LSTM cells. TensorFlow will throw an error if the weights created here have the same names as the weights created in the LSTM cells, which they will be default. To avoid this, we wrap the variables in a variable scope so we can give them unique names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        lstm_output: List of output tensors from the LSTM layer\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells\n",
    "        out_size: Size of this softmax layer\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Reshape output so it's a bunch of rows, one row for each step for each sequence.\n",
    "    # Concatenate lstm_output over axis 1 (the columns)\n",
    "    seq_output = tf.concat(lstm_output,axis=1)\n",
    "    # Reshape seq_output to a 2D tensor with lstm_size columns\n",
    "    x = tf.reshape(seq_output,[-1,in_size])\n",
    "    \n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        # Create the weight and bias variables here\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size),stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros([out_size]))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits =  tf.add(tf.matmul(x,softmax_w),softmax_b) \n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits,name =\"out\")\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loss\n",
    "\n",
    "Next up is the training loss. We get the logits and targets and calculate the softmax cross-entropy loss. First we need to one-hot encode the targets, we're getting them as encoded characters. Then, reshape the one-hot targets so it's a 2D tensor with size $(M*N) \\times C$ where $C$ is the number of classes/characters we have. Remember that we reshaped the LSTM outputs and ran them through a fully connected layer with $C$ units. So our logits will also have size $(M*N) \\times C$.\n",
    "\n",
    "Then we run the logits and targets through `tf.nn.softmax_cross_entropy_with_logits` and find the mean to get the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, num_classes):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    # One-hot encode targets and reshape to match logits, one row per sequence per step\n",
    "    y_one_hot = tf.one_hot(targets,num_classes)\n",
    "    y_reshaped =  tf.reshape(y_one_hot,logits.get_shape())\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y_reshaped))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Here we build the optimizer. Normal RNNs have have issues gradients exploding and disappearing. LSTMs fix the disappearance problem, but the gradients can still grow without bound. To fix this, we can clip the gradients above some threshold. That is, if a gradient is larger than that threshold, we set it to the threshold. This will ensure the gradients never grow overly large. Then we use an AdamOptimizer for the learning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip,global_step):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        global_step: to control the total number of train steps\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars),global_step)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network\n",
    "\n",
    "Now we can put all the pieces together and build a class for the network. To actually run data through the LSTM cells, we will use [`tf.nn.dynamic_rnn`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/dynamic_rnn). This function will pass the hidden and cell states across LSTM cells appropriately for us. It returns the outputs for each LSTM cell at each step for each sequence in the mini-batch. It also gives us the final LSTM state. We want to save this state as `final_state` so we can pass it to the first LSTM cell in the the next mini-batch run. For `tf.nn.dynamic_rnn`, we pass in the cell and initial state we get from `build_lstm`, as well as our input sequences. Also, we need to one-hot encode the inputs before going into the RNN. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False):\n",
    "    \n",
    "        # When we're using this network for sampling later, we'll be passing in\n",
    "        # one character at a time, so providing an option for that\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.global_step_tensor = tf.Variable(0,trainable=False,name = \"global_step\")\n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size,num_steps)\n",
    "        # Build the LSTM cell\n",
    "        cell, self.initial_state = build_lstm(lstm_size,num_layers,batch_size,self.keep_prob)\n",
    "        ### Run the data through the RNN layers\n",
    "        # First, one-hot encode the input tokens\n",
    "        x_one_hot = tf.one_hot(self.inputs,num_classes)\n",
    "        \n",
    "        self.grad_clip  = grad_clip\n",
    "        # Run each sequence step through the RNN with tf.nn.dynamic_rnn \n",
    "        outputs, state = tf.nn.dynamic_rnn(cell,x_one_hot,initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Get softmax predictions and logits\n",
    "        self.prediction, self.logits = build_output(outputs,lstm_size,num_classes)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss =  build_loss(self.logits,self.targets,lstm_size,num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss,learning_rate,grad_clip,self.global_step_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Here are the hyperparameters for the network.\n",
    "\n",
    "* `batch_size` - Number of sequences running through the network in one pass.\n",
    "* `num_steps` - Number of characters in the sequence the network is trained on. Larger is better typically, the network will learn more long range dependencies. But it takes longer to train. 100 is typically a good number here.\n",
    "* `lstm_size` - The number of units in the hidden layers.\n",
    "* `num_layers` - Number of hidden LSTM layers to use\n",
    "* `learning_rate` - Learning rate for training\n",
    "* `keep_prob` - The dropout keep probability when training. If you're network is overfitting, try decreasing this.\n",
    "\n",
    "Here's some good advice from Andrej Karpathy on training the network:. \n",
    "\n",
    "> ## Tips and Tricks\n",
    "\n",
    ">### Monitoring Validation Loss vs. Training Loss\n",
    ">If you're somewhat new to Machine Learning or Neural Networks it can take a bit of expertise to get good models. The most important quantity to keep track of is the difference between your training loss (printed during training) and the validation loss (printed once in a while when the RNN is run on the validation data (by default every 1000 iterations)). In particular:\n",
    "\n",
    "> - If your training loss is much lower than validation loss then this means the network might be **overfitting**. Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on.\n",
    "> - If your training/validation loss are about equal then your model is **underfitting**. Increase the size of your model (either number of layers or the raw number of neurons per layer)\n",
    "\n",
    "> ### Approximate number of parameters\n",
    "\n",
    "> The two most important parameters that control the model are `lstm_size` and `num_layers`. I would advise that you always use `num_layers` of either 2/3. The `lstm_size` can be adjusted based on how much data you have. The two important quantities to keep track of here are:\n",
    "\n",
    "> - The number of parameters in your model. This is printed when you start training.\n",
    "> - The size of your dataset. 1MB file is approximately 1 million characters.\n",
    "\n",
    ">These two should be about the same order of magnitude. It's a little tricky to tell. Here are some examples:\n",
    "\n",
    "> - I have a 100MB dataset and I'm using the default parameter settings (which currently print 150K parameters). My data size is significantly larger (100 mil >> 0.15 mil), so I expect to heavily underfit. I am thinking I can comfortably afford to make `lstm_size` larger.\n",
    "> - I have a 10MB dataset and running a 10 million parameter model. I'm slightly nervous and I'm carefully monitoring my validation loss. If it's larger than my training loss then I may want to try to increase dropout a bit and see if that helps the validation loss.\n",
    "\n",
    "> ### Best models strategy\n",
    "\n",
    ">The winning strategy to obtaining very good models (if you have the compute time) is to always err on making the network larger (as large as you're willing to wait for it to compute) and then try different dropout values (between 0,1). Whatever model has the best validation performance (the loss, written in the checkpoint filename, low is good) is the one you should use in the end.\n",
    "\n",
    ">It is very common in deep learning to run many different models with many different hyperparameter settings, and in the end take whatever checkpoint gave the best validation performance.\n",
    "\n",
    ">By the way, the size of your training and validation splits are also parameters. Make sure you have a decent amount of data in your validation set or otherwise the validation performance will be noisy and not very informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_number_of_parameters():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        shape = variable.get_shape()\n",
    "        #print(shape)\n",
    "        #print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        \n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parameters*=dim.value\n",
    "        #print(variable_parameters)\n",
    "        total_parameters+= variable_parameters\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for training\n",
    "\n",
    "This is typical training code, passing inputs and targets into the network, then running the optimizer. Here we also get back the final LSTM state for the mini-batch. Then, we pass that state back into the network so the next batch can continue the state from the previous batch. And every so often (set by `save_every_n`) I save a checkpoint.\n",
    "\n",
    "Here I'm saving checkpoints with the format\n",
    "\n",
    "`i{iteration number}_l{# hidden layer units}.ckpt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = {\"train\":[],\"validation\":[]}\n",
    "x_steps = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting at time: 2017-10-16 03:10:36\n",
      "Number of parameters: 7475814 Dataset size: 2563420\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i4005_l768.ckpt\n",
      "Epoch: 1/15...  Training Step: 4006...  Training loss: 1.1225...  Val loss: 1.6267...  0.3459 sec/batch\n",
      "Epoch: 1/15...  Training Step: 4106...  Training loss: 1.0191...  Val loss: 1.5808...  0.2977 sec/batch\n",
      "Epoch: 1/15...  Training Step: 4206...  Training loss: 1.0002...  Val loss: 1.5812...  0.2819 sec/batch\n",
      "Epoch: 2/15...  Training Step: 4306...  Training loss: 0.9500...  Val loss: 1.6059...  0.2996 sec/batch\n",
      "Epoch: 2/15...  Training Step: 4406...  Training loss: 0.9257...  Val loss: 1.6281...  0.3051 sec/batch\n",
      "Epoch: 2/15...  Training Step: 4506...  Training loss: 0.9340...  Val loss: 1.6455...  0.3031 sec/batch\n",
      "Epoch: 3/15...  Training Step: 4606...  Training loss: 0.9251...  Val loss: 1.6442...  0.3049 sec/batch\n",
      "Epoch: 3/15...  Training Step: 4706...  Training loss: 0.8682...  Val loss: 1.6789...  0.3046 sec/batch\n",
      "Epoch: 3/15...  Training Step: 4806...  Training loss: 0.8838...  Val loss: 1.6925...  0.3028 sec/batch\n",
      "Epoch: 4/15...  Training Step: 4906...  Training loss: 0.8465...  Val loss: 1.7090...  0.3027 sec/batch\n",
      "Epoch: 4/15...  Training Step: 5006...  Training loss: 0.8572...  Val loss: 1.7175...  0.3063 sec/batch\n",
      "Epoch: 5/15...  Training Step: 5106...  Training loss: 0.8357...  Val loss: 1.7424...  0.3049 sec/batch\n",
      "Epoch: 5/15...  Training Step: 5206...  Training loss: 0.8063...  Val loss: 1.7694...  0.3017 sec/batch\n",
      "Epoch: 5/15...  Training Step: 5306...  Training loss: 0.8229...  Val loss: 1.7729...  0.3053 sec/batch\n",
      "Epoch: 6/15...  Training Step: 5406...  Training loss: 0.7853...  Val loss: 1.7800...  0.2915 sec/batch\n",
      "Epoch: 6/15...  Training Step: 5506...  Training loss: 0.7652...  Val loss: 1.8214...  0.2784 sec/batch\n",
      "Epoch: 6/15...  Training Step: 5606...  Training loss: 0.7934...  Val loss: 1.8321...  0.2769 sec/batch\n",
      "Epoch: 7/15...  Training Step: 5706...  Training loss: 0.7717...  Val loss: 1.8498...  0.2758 sec/batch\n",
      "Epoch: 7/15...  Training Step: 5806...  Training loss: 0.7639...  Val loss: 1.8499...  0.2765 sec/batch\n",
      "Epoch: 8/15...  Training Step: 5906...  Training loss: 0.7908...  Val loss: 1.8709...  0.2770 sec/batch\n",
      "Epoch: 8/15...  Training Step: 6006...  Training loss: 0.7733...  Val loss: 1.8774...  0.2771 sec/batch\n",
      "Epoch: 8/15...  Training Step: 6106...  Training loss: 0.7959...  Val loss: 1.8785...  0.2769 sec/batch\n",
      "Epoch: 9/15...  Training Step: 6206...  Training loss: 0.7717...  Val loss: 1.8758...  0.2774 sec/batch\n",
      "Epoch: 9/15...  Training Step: 6306...  Training loss: 0.7631...  Val loss: 1.9273...  0.2766 sec/batch\n",
      "Epoch: 9/15...  Training Step: 6406...  Training loss: 0.7602...  Val loss: 1.8978...  0.2769 sec/batch\n",
      "Epoch: 10/15...  Training Step: 6506...  Training loss: 0.7371...  Val loss: 1.9144...  0.2848 sec/batch\n",
      "Epoch: 10/15...  Training Step: 6606...  Training loss: 0.7422...  Val loss: 1.9250...  0.2760 sec/batch\n",
      "Epoch 10/15 time:74.48389005661011...  finished at 2017-10-16 03:23:37\n",
      "Epoch: 11/15...  Training Step: 6706...  Training loss: 0.7300...  Val loss: 1.9698...  0.2769 sec/batch\n",
      "Epoch: 11/15...  Training Step: 6806...  Training loss: 0.7170...  Val loss: 1.9742...  0.2767 sec/batch\n",
      "Epoch: 11/15...  Training Step: 6906...  Training loss: 0.6884...  Val loss: 1.9740...  0.2772 sec/batch\n",
      "Epoch: 12/15...  Training Step: 7006...  Training loss: 0.6900...  Val loss: 2.0004...  0.2763 sec/batch\n",
      "Epoch: 12/15...  Training Step: 7106...  Training loss: 0.6690...  Val loss: 2.0041...  0.2767 sec/batch\n",
      "Epoch: 12/15...  Training Step: 7206...  Training loss: 0.6729...  Val loss: 2.0366...  0.2766 sec/batch\n",
      "Epoch: 13/15...  Training Step: 7306...  Training loss: 0.6583...  Val loss: 2.0199...  0.2772 sec/batch\n",
      "Epoch: 13/15...  Training Step: 7406...  Training loss: 0.6885...  Val loss: 2.0080...  0.2766 sec/batch\n",
      "Epoch: 14/15...  Training Step: 7506...  Training loss: 0.6472...  Val loss: 2.0590...  0.2766 sec/batch\n",
      "Epoch: 14/15...  Training Step: 7606...  Training loss: 0.6601...  Val loss: 2.0657...  0.2759 sec/batch\n",
      "Epoch: 14/15...  Training Step: 7706...  Training loss: 0.6363...  Val loss: 2.0924...  0.2771 sec/batch\n",
      "Epoch: 15/15...  Training Step: 7806...  Training loss: 0.6451...  Val loss: 2.1102...  0.2770 sec/batch\n",
      "Epoch: 15/15...  Training Step: 7906...  Training loss: 0.6541...  Val loss: 2.1227...  0.2767 sec/batch\n",
      "Epoch: 15/15...  Training Step: 8006...  Training loss: 0.6159...  Val loss: 2.1668...  0.2772 sec/batch\n",
      "Training ending at time: 2017-10-16 03:29:49\n",
      "Trainint total time: 1152.564558506012\n"
     ]
    }
   ],
   "source": [
    "#epochs = 1\n",
    "# Save every N iterations\n",
    "save_every_n = 500\n",
    "print_loss_every_n = 100\n",
    "sample_every = 500\n",
    "print_epoch_time_every = 10\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "    #print(\"after model\")\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "print(\"Training starting at time:\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "train_start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Number of parameters:\",get_number_of_parameters(),\"Dataset size:\",len(encoded))\n",
    "    #print(\"after initializer\")\n",
    "    if resume_from_checkpoint:\n",
    "        latest_checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "        saver.restore(sess, latest_checkpoint)\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Train network\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            \n",
    "            \n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "        \n",
    "            \n",
    "            end = time.time()\n",
    "            if counter%print_loss_every_n == 0:\n",
    "                val_batches = get_batches(encoded_val,int(len(encoded_val)/num_steps),num_steps)\n",
    "                x_val,y_val = next(val_batches)\n",
    "                \n",
    "                val_dict = {model.inputs: x_val,\n",
    "                            model.targets: y_val,\n",
    "                            model.keep_prob: 1,\n",
    "                            model.initial_state: new_state}\n",
    "                \n",
    "                val_loss,prediction = sess.run([model.loss,model.prediction],feed_dict=val_dict)\n",
    "                \n",
    "                losses[\"train\"].append(batch_loss)\n",
    "                losses[\"validation\"].append(val_loss)\n",
    "                \n",
    "                \n",
    "                global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "                x_steps.append(global_step)\n",
    "                \n",
    "                print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                      'Training Step: {}... '.format(global_step),\n",
    "                      'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                      'Val loss: {:.4f}... '.format(val_loss),\n",
    "                      '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "                saver.save(sess, \"checkpoints/m{}_i{}_l{}.ckpt\".format(mode,global_step, lstm_size))\n",
    "                \n",
    "            counter += 1\n",
    "            #learning_rate*=0.75\n",
    "            #model.optimizer = build_optimizer(model.loss,learning_rate,model.grad_clip,model.global_step_tensor)\n",
    "        \n",
    "        epoch_end = time.time()\n",
    "        \n",
    "        \n",
    "        if ((e+1) % print_epoch_time_every== 0):\n",
    "            print('Epoch {}/{} time:{}...'.format(e+1,epochs,epoch_end-epoch_start),\n",
    "                 \" finished at\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "        \n",
    "            \n",
    "    global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "    saver.save(sess, \"checkpoints/m{}_i{}_l{}.ckpt\".format(mode,global_step, lstm_size))\n",
    "    \n",
    "print(\"Training ending at time:\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "print(\"Trainint total time:\",time.time()-train_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAH0CAYAAACEkWPuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa0a810d208>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 373
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_steps,losses[\"train\"],label=\"Train loss\")\n",
    "plt.plot(x_steps,losses[\"validation\"],label=\"Validation loss\")\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saved checkpoints\n",
    "\n",
    "Read up on saving and loading checkpoints here: https://www.tensorflow.org/programmers_guide/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoints = tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling final trained model\n",
    "\n",
    "Now that the network is trained, we'll can use it to generate new text. The idea is that we pass in a character, then the network will predict the next character. We can use the new one, to predict the next one. And we keep doing this to generate all new text. I also included some functionality to prime the network with some text by passing in a string and building up a state from that.\n",
    "\n",
    "The network gives us predictions for each character. To reduce noise and make things a little less random, I'm going to only choose a new character from the top N most likely characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \",mode=\"characters\"):\n",
    "    print(mode)\n",
    "    samples = tokenize_text(prime,mode)\n",
    "    model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in tokenize_text(prime,mode):\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples).replace(\"new_line_token\",\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, pass in the path to a checkpoint and sample from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/mcharacters_i8010_l768.ckpt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new text from \"base\" text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "\n",
    "\n",
    "samples = list()\n",
    "for text in text_to_try:\n",
    "    #print(\"------------------------\",text)\n",
    "    samples.append( sample(checkpoint, 500, lstm_size, len(vocab), prime=text,mode=mode))\n",
    "    #print(samp)\n",
    "    #print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ In the first place\n",
      "In the first place, it is probable I had a week of particular below, and a neglect of terror, therve in general confactual horror, and carefully sheer impression under the shoulder days; suffersed, sight,ling, and short monstrous and pink-black peders of vessels; but to accomplinh were groping and horrible drynching almost animal weithers, wite could never have cross a torch betaious bridges being very base to my fingers; th shivering, and\n",
      "threw the whole sort of feeble annaysistance, lowering, and starfish-poinde\n",
      "------------------------\n",
      "------------------------ the night before\n",
      "the night before, or though he was at all ends, there studied by another\n",
      "structure because of the choked than him of his hands upon his breath as\n",
      "debreak, and had apparently been setting along it two or together up secretling among them.\n",
      "     After that no purpose was detertion, and distinct the\n",
      "apparition of chorused roof,\n",
      "and was readily choked me with luminosine points. These\n",
      "predaces of the women and feated shells hung borne out from with a problemation; and had at once endeavoured to reach\n",
      "eater tonferous a\n",
      "------------------------\n",
      "------------------------ horror\n",
      "horror my own height windows above their heads. He had secured, and of the sunset set forth infinithering a projuced wizd and easy candles, and peridd uponably heomed me to set if he\n",
      "must let greatly incredibly for connecting upon the portion of its identic circles and or twice involvet, and seemed to cover up food another approaching about\n",
      "advessard matters which the youth had comparatively run ourreluboubly drowsing browled, and all cultus, be learned, affected by mesorional sensesoms of entry. All s\n",
      "------------------------\n",
      "------------------------ creature\n",
      "creature and reduced covering over all-very bew louthern itself. The belliess and supporting door would be gladedted. Over a countenablish-headed beings can for any studdenner imminent act of outpost,ays of a beilficulated charce of immortabes that oftended to these profounn.s and that a record-robabome of character sprinklings were set in tangibly theoromestic chaos of mockingly had a dorthside lasted several smiles, demanified things that were murderously made our way of a tall, lighting palms that wer\n",
      "------------------------\n",
      "------------------------ night\n",
      "nighte.\n",
      "\n",
      "The night was carefully\n",
      " whisted that the brig nool was being in a glass of brooding our presence in that abyss of intimate and supporting clouds, and sawthat these arms were clearly shut of my coat, commusications in reduces of modern terror, and that the abstracted manual in chasm, this was, as\n",
      "crowned by the flore in the hollowful east of the hall.\n",
      "\n",
      "And now, at if ever one, there came betweer\n",
      "witches three first I desifed, the pride of his hutsent roof. They have a tripletial invecile, co\n",
      "------------------------\n",
      "------------------------ dream\n",
      "dreaments with that curious gatex and gables, for a brief period when indicated those destroying tenests at ninetice whom the storms how floated and holds unberranted three the hills and reclosant tethered titary assemblitwer streets at night, and what way he was agnestablish in a new impression that the main building scrowl would run, and that he knew he pendedry and we sloped away from the trobless and bearing state. One insidious automatory raving brideway audnesses to the centre. There had been a \n",
      "------------------------\n",
      "------------------------ thing\n",
      "things sinisterbable that they could not, and too, that his whole extendive canic, since the least shapeless room toowned and talked on all simi-mouthed abnormality. All that the friends are very poudd, and thet gigantic secret down to large the accursed roof was seen. Their voices had been seized by the shoring ropes, and he did not envely in truth a level of grimpsent mind of solution of those persons to tell, of course and counteary of man, and the accident of the cropped blocks happen and pieces o\n",
      "------------------------\n",
      "------------------------ That night\n",
      "That nightful family will not be much impossible. I may alarmed and\n",
      "startlingly assured me from my perception. Through this chance of an\n",
      "operason was much more in her own house it is mounted in the country a hore, and\n",
      "throst immediately drowning strange outline and serving the raicto\n",
      "     The obtain being the bricking of his grandfathe feeble words in fancy, that I had noticed the shorter countryside beyond and perfect she curiously disjointed, in reading\n",
      "the post, but conjectually more than a few hours af\n",
      "------------------------\n",
      "------------------------ mountain\n",
      "mountainous richmentfrous slaves geological. He could not return to nooly hoverible about how explain, and\n",
      "what actual she must be taken if more horrorful that I scarcely kis horrors of the hogs. Tet these heredoom, and\n",
      "sixteen battery, as if I were to be about to sleep -- dawn--never worm, to attabon, and the albatrossen ago vaulting alone wore of a dead couptivilus. The result was now driven in from the trutching motion, with\n",
      "sounds all the fourther or follywadds, and mere pororoganoo\n",
      "and nervous beint\n",
      "------------------------\n",
      "------------------------ Ammi\n",
      "Ammi Makely, and add along the phantasm of countenance in theheur colons. The muse of the most singular bounds, and in the belt upon a deck which had been a mortal abomination of live-garders. Sloops, took, and research, were represented in my ears. They remained night a measure before my on which I was awaken, and even if it was\n",
      "thus for me that I could not have taken to the precaution of hand. He say\n",
      "alarge horror might be\n",
      "seen low, whilst it is this expectancy was a very fatage on the\n",
      "corroporatio\n",
      "------------------------\n",
      "------------------------ Cthulhu\n",
      "CthulhuKs Mighty was comparative by the great world and musty wales. Toward tswarhs grounds on that mighty moving delicipations which fastened in the unshard never wasmay. That fell afternate found pointed odder dressed the speaker among gassings bying certain which would pleasleng from my original domain, however, above the larboard gand.\n",
      "     The records of the montt, how altogether upon the ground of brambles, tiget, at first, ten feet late, with its fute from a passionance.\n",
      "\n",
      "As we have, my dreams in\n",
      "------------------------\n",
      "------------------------ raven\n",
      "ravening grave and sort, some of which we ensuevered that he had so lurked a difference; though a single who apoced him which we writtently cannot. Afroih there was a huge coffin-was necessary. Th  - this man was rathering to unharried them, and hearding the cornert, a ground planet abysses bet men in dark, upon this sincl of these thressombred times. There is a row of a disphiration and open space about through the\n",
      "bulky, most among other child to that\n",
      "whose terror was at least admitable--and a newly\n",
      "------------------------\n",
      "------------------------ bird\n",
      "bird if the Manuxet. Mysteal is cheered, but I do not would have tarred to us, and began to asserve it any of the proding of his more through which we exceeds a man of strange and sharp febrasts against the shadge, waiting forepays.\n",
      "\n",
      "    Our far too late had been removed, as before, between ten or two farther from\n",
      "throat of its terrift, and did what again he told ever the party as hung, but was always vasting despite the abundane, who formed the towering outstrustical at the associated whining-positi\n",
      "------------------------\n",
      "------------------------ nevermore\n",
      "nevermores,\n",
      "earthonged and gulyshold. The shread of a very singularly dogs above the stars. The nebroar archways of the Grampus was a discoverable places where name of the chamber Gods happened to frequrn to clotch they trgund to form nightmare clouds, while a gentle barking and hard-greatest abnormal times spirifically spites to be compared as a negro, through that of their consciousness and terribled dangerous assemblage of our knives, and of the sented stratumits of groupers because of the ghouls and n\n",
      "------------------------\n",
      "------------------------ dead\n",
      "dead.\n",
      "\n",
      "The adaqtain was unclouded about three feet when each larger at the sides were frankly of servents. Then thus, in a low mad confess of feeling most abandon\n",
      "un aspect, with a stupition that he\n",
      "would have glasses and\n",
      "dreams of hills, and everybody entering into the black, and beginnou doubt the bowily of the\n",
      "ground. On this time two pulleps sounds, which came finally connected his fail; and thatified of all my lumber on that hellish and image and a half-in the\n",
      "frightful distances, and we were fo\n",
      "------------------------\n",
      "------------------------ The bird\n",
      "The birds of the rock; beiled, racked,\n",
      "and allowing in the neighbouring tale, was apparently ruinour entity. He could\n",
      "not resist the folklore of hysterical limeness in accrumable buried in the shadow.\n",
      "\n",
      "    Three wareous waiss, I madetathly accordingly because of my courchary\n",
      "perusiveness of his\n",
      "own, and deathlights, together with a particle of a general or level as the roofices gliberaugery in the night. The condition of Augustus\n",
      "had, I met the gentlemen of gloot agains in sail. In ret times, rattless in\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(text_to_try)):\n",
    "    text = text_to_try[i]\n",
    "    generated = samples[i]\n",
    "    print(\"------------------------\",text)\n",
    "    print(generated)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/mcharacters_i8010_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i6506_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i7006_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i7506_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i8006_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i8010_l768.ckpt\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "The old folk have gone away, for that we had now to be at all buried on or twenty-fifth passed the most\n",
      "convenient places in about a third execution. As we could out would be only to picture to imbuls and abnormality. This wild an unusual palpable forecasual remotest, a briggerent indicative glance, where, too, there could be the merciful open the lower longures, when we wereful agoni block in my dangered, barrenin, time-times --incluiovable and priest-wabousness, were not filled ephousingly by means of a scara;\n",
      "but the paws and libera-complex which immediately took up and footfully predentingly in the person who turned the\n",
      "last general cover, with coursed villages of the soul.\n",
      "\n",
      "    Thus at length I scrambled my bolted thin, shou descended forth there is, and this in a sentimentaki,htht,out wait-combands in the chamber --or what we weigh, that this was overposed, in a kind of probably worry, to the abomadest compation of my situation. I recalled any language for some minutes, and I ever for morrifur immoniateless th it instantaneous.\n",
      "\n",
      "    In about an hour, we would get to ind, and that they would claim that this was wondered; and in any respect that I before said to have a conclusion that I can say that I stood around the nail, and I have many\n",
      "pronounces and perhaps, in opium didected upon this purpose? I did so, and then the tentacles of the mountains of burning, all-venturn to that\n",
      "chiefacts -- a mad cas-a noise accursed for his aid, being shudderingly, and his bride rumb, bt the inconspicoous rycrepancy, to without the patches of good fortune in\n",
      "every direction. There was a respiration of papers, we must have\n",
      "been employed or was\n",
      "full to all the affairs had built usefine with through walls and shambling voice, subsidous and\n",
      "bas-ressesses\n",
      "I required an Enizmanoly voice, that the archway arose from Mesorog Coff, therefore, after all to operations oe two of the most sensible or ellierce. Shall I lafting resorred myself for being possession of the abundant moonlig wits by\n",
      "which I festure my eyes shouldered\n",
      "in the end if if the\n",
      "futifishing sublicity as I have that even to obtain I could thisk or minute, about oy, with a view of a great deal of wine.\n",
      "\n",
      "A ward, thick terrace upon the troubled verticaned quietly peaceful horror about those delivered antarctic was shaken in the\n",
      "course of a long lever would be.\n",
      "     I now found that I had so dropsed but one of those others shooting definite, a brata on yard, down their finally did repeat through i suiled hills, while the abroance of his countenanel was a blasphe of balls,lingnessed books, sails, celarrised, windowless in every powers or two acts of infinite\n",
      "stages but from the\n",
      "point of with a vague surface. The chossis help amiss oversiphers, and so fell by the bruse of a melancholy and more monal tough only wound. Alas! the sails and telling of this could have brown a flast after either side of the walls, with\n",
      "singulance in which these very exposed attonis in arranging through these chains and wint-reassanies, whith would have noticed the terror and three hundred and ten feet wide about which I had at first belond it\n",
      "out.'\n",
      "\n",
      "\n",
      "\n",
      "These eathness I have not been above the limits of my horrens, and my meaning in the chose, drifting, at the evening of the nursear and perhaps handled, I soon remarked, who soon resorted to feel that a few feet were fastening. They ate these modes that ten that I could say with their complex ones, by scholars and ports brought so fer strong caverils behind\n",
      "a most detailing cryptical stream of me from my soul old Zecul contaity, thatched their correcting sounds in the rays of perfect silences. It was a very remarkable chaos, but he dares would enter again upon any the portentous momentous cats of puzzlic into which it\n",
      "made him by way of comparatively marvellous of its bolt. A time had always frightening him to them. The said splare, which none of the\n",
      "best of meteor, sank, over it, which were sculptured; but, indeed, I found myself at least to me seemed some\n",
      "rapidly,\n",
      "as if I spoked muchine, and talked one or two in a strong blow were\n",
      "strown with right greenish by my eye--and as I could, together and endresting terror, and had a third far\n",
      "mirecalling what all the familiare itself was straightly frightful, as if the wind water the motions of mountains, my rame, randomed than hopefeering, of which he had been\n",
      "proceeled\n",
      "up as everall across the walls of the crypt\n",
      "and myself. He seemed so limitleed in a kind of speculations, and in spite of a diseased manner, with the most violent extiectness of the prodigious --dutailed, but could not, every moment. In rethests I saw the mercy, of coursen, are flutted more than once frightening in the countenance that we should find the less imoth in dream or mart. I am consoled to my driveral globoly and\n",
      "sestimy became very carriated,ork,\n",
      "Peters on the time of the thirdent sailed to their own fute death. In\n",
      "an Inspecies, thelody nameless eyes I became cruzed forthwith, and arrowaged rim myths belonging to me. That sheng, had caused much of \n"
     ]
    }
   ],
   "source": [
    "generated = sample(checkpoint, 5000, lstm_size, len(vocab), prime=\"The old folk have gone away\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i8010_l768.ckpt\n",
      "The thing that should not becompleted over every thing inconclusivity; but when adopted me, and had never before seen a most silent and eager and inferred. It was no daramatic nehur and superout once a place, and visible beyond the days of the brink, like that they were evidently. I was by known to the table, and studied by every meat his disgroppror ts as that the one perspering houses of the shore. He was now\n",
      "struck upon the head wild, windows of a\n",
      "sinisher\n",
      "ir, and of the solid walls sented the boat, with a back and findished drift loons; and by either passevers of the strong extenations,\n",
      "he po were set off to the\n",
      "southward and weathering genual in\n",
      "spasmodic exists. The condition, with its full and rather discoursed; for surrob my controwness, I struck my own apprehension, the stone was, sailed, and terrible forthwithout\n",
      "attempting anoundwhathe, but to safe together in tseeth to account in\n",
      "this posspical myself so hand, and\n",
      "was blastedied upon me beeod-corredares. Though play at whalve a gimmness of accurse -for he had true and perceivable experience a vhillting of\n",
      "satisfierct --where by centring would be retached from the action of the parallel by any existence. Squitring them, in some measure,I was urger, I could have instructous bring of the more agedies, and\n",
      "at once starking it our words --a was as possible, and we brought awf ragesters of the corner of the\n",
      "stream. The building were fed\n",
      "from the investigation of the\n",
      "court;arks in the whole marked being of a portion of their\n",
      "seams. A sensationsomners was cau in an oaky, opening through a window, getting\n",
      "out, and those who probebly, too, thus at the floor, and apparented it\n",
      "of being vorr in our father, with all my ultin toward myself. We found that time, to having been thun two\n",
      "fainting and terribleally hour, with soupendent and narules to encourage any of these modes undeceded; of a dream, I found that several countryses were so that at the\n",
      "absence of my perspective and phenomenon, after letting more prominent to the most absolute nupboard of which the cords cauliously rgad. But then, though, with the melody of Joseph Curwen's courago.\n",
      "\n",
      "This horror ancient bals are passed through a rope which there were many inclined, the object betwixt to him, were not uncovered\n",
      "before. To my right,mard telling of the countryside me, my first started thing, it is three influences forthwith, hab, in abysobic tones furnime, and very consequently down against its which a thousand child of water,\n",
      "which in the awful moments\n",
      "with grassing instruments, which comparfulently\n",
      "did not\n",
      "believe) our word and preparive metallic and almost monstrous pinkish foresters, and to so, he had never beheld, with any eyes, have grown upon that, although for it at oncessioned particularspre of the terribal objectfe-sunned opensions, but with great care, the crew was clear again and sudden and tendency to the curvey explosing odogr.ese to the north and weisted in the ship, and extending\n",
      "had poisoned that we had begun to find, at other portions of those storm-rooms wite could get at them in every direction two libraries and perfect contact with any distant above and everything which had much above his words. The head of those great masts now thoroughly, only, which patiently from some terrible fast as soon as I have expected to find the\n",
      "reary\n",
      "element of every action which had at\n",
      "first, be rendered in our\n",
      "buist, and very step in the most horrible and\n",
      "problematiel. Willett said haddly as we might thus edd it on\n",
      "for the point of visible fresh itsolation, were not to consolable me to be\n",
      "spiringless. In one of his\n",
      "son, one or two, that one or though no steps were ruddlinguage. There were severally though was strange abstract of this return,\n",
      "and one of our\n",
      "proportion to the handwriting, I must have actuate to me, and I\n",
      "had not the least, and most di fortunate objects of\n",
      "the stark,\n",
      "about whose feverish being made to the farther front of the shorter; and, at this\n",
      "period upon the product of anoialieuc and\n",
      "darkness, with the eagerment of our ordinary until supreclume, throughout the\n",
      "whole object, ine statues about\n",
      "as long as a\n",
      "movement of boat, or myself,\n",
      "along which\n",
      "I thought the bolt of the box.\n",
      "\n",
      "    \"Glazon,\" hearly, thanfash together with this nighte. Tumnic bury, noonfused work--he would allow me in a briot almost evident sound but throwe me a customary at all, but it ise to be sure, from the mate in every respecm to state\n",
      "the\n",
      "seasons. Sleeple on a widdor down, us with a throne--a hard in the confession so terrible for miles and foreigners. The limbs he replaced my friend by the friend, above all, I am impossible to connect any lure a scarioal obstrentimy, with southerm of his solid ranke werewhood. How to go to Throught the florcting with its leagrers of deserteless and infinite stalage of the door, without any respect to my bring his progress toward a temper; aftervaud, I beheld a short white, widow- and impatuents, and I saw that the breadth would hesitation in any immemorial freatiness through a tanging sort that subjected\n"
     ]
    }
   ],
   "source": [
    "generated = sample(checkpoint, 5000, lstm_size, len(vocab), prime=\"The thing that should not be\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
